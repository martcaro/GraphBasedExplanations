{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "import math\n",
    "# Documentacion de la libreria: http://networkx.readthedocs.io/en/networkx-1.11/\n",
    "\n",
    "from operator import itemgetter\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS \n",
    "\n",
    "#DATASET_SIZE = 100000\n",
    "#HALF_DATASET_SIZE = int(DATASET_SIZE / 2)\n",
    "RATING_THRESHOLD = 4\n",
    "WEIGHT_THRESHOLD = 5\n",
    "K = 10\n",
    "MEASURES = ['aa', 'cn', 'ew', 'jn', 'pa', 'waa', 'wcn', 'wpa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS AND SUBPROGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareNodes(f_list, s_list):\n",
    "    \"\"\"\n",
    "        Function that returns the number of users that have interact with both items\n",
    "        Funcion que devuelve el numero de usuarios que han interactuado con ambos items\n",
    "    \"\"\"\n",
    "    peso = len(np.intersect1d(f_list, s_list))\n",
    "    \n",
    "    return peso\n",
    "    \n",
    "def createLinks(prob_us_set, nodos, threshold):\n",
    "    \"\"\"\n",
    "        Function that creates graph links with the information about the set. The weight has to be grater or equal to threshold.\n",
    "        \n",
    "        Funcion que crea los enlaces del grafo a partir de la informacion contenida en el conjunto que se le\n",
    "        pasa a la funcion. El peso tiene que ser mayor o igual al umbral.\n",
    "        \n",
    "        Format of links list -> [(Node1, Node2, weight), ......]\n",
    "    \"\"\"\n",
    "    resultado = list() \n",
    "    \n",
    "    # hago todas las posibles combinaciones de problemas\n",
    "    for fst, snd in it.combinations(nodos, 2):\n",
    "        # obtengo el peso pasando la lista de usuarios que ha hecho cada problema\n",
    "        peso = compareNodes(prob_us_set[fst], prob_us_set[snd])\n",
    "        if peso >= threshold:\n",
    "            resultado.append((fst, snd, peso))\n",
    "            \n",
    "            \n",
    "            \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_nx(list_nodes, list_links):\n",
    "    \"\"\"\n",
    "        Function that creates a graph with the format from NetworkX \n",
    "        \n",
    "        Funcion que crea un grafo de tipo Graph de la libreria NetworkX\n",
    "        Construccion del grafo: http://networkx.readthedocs.io/en/networkx-1.11/tutorial/tutorial.html#what-to-use-as-nodes-and-edges\n",
    "    \"\"\"\n",
    "    grafo = nx.Graph() # creo la variable grafo\n",
    "\n",
    "    # incluyo los nodos del grafo \n",
    "    grafo.add_nodes_from(list_nodes)\n",
    "\n",
    "    # se incluyen las tuplas de enlaces con el peso del enlace\n",
    "    # es una lista de la forma [(Nodo1, Nodo2, peso), ......]\n",
    "    grafo.add_weighted_edges_from(list_links)\n",
    "\n",
    "    return grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_aa(row, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve para cada par de nodos, el sumatorio de 1/log(N(z)), siendo N(z) el grado del nodo z para todo z \n",
    "        perteneciente al conjunto de nodos en comun de ese par de nodos\n",
    "    \"\"\"\n",
    "    \n",
    "    # obtengo un iterador de un solo elemento que tiene en la tercera posicion el valor de AA para el par de nodos\n",
    "    value = nx.adamic_adar_index(graph, [(row['one'], row['two'])])\n",
    "    \n",
    "    value_aa = 0\n",
    "    for u, v, p in value:\n",
    "        # itero el iterador, guardando el valor de adar adamic\n",
    "        value_aa = p\n",
    "    \n",
    "    return value_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cn(row, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve el numero de vecinos en comun de esos dos nodos\n",
    "    \"\"\"\n",
    "    return len(list(nx.common_neighbors(graph, row['one'], row['two'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ew(row, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve el peso del enlace en cada par\n",
    "    \"\"\"\n",
    "    fst = row['one']\n",
    "    snd = row['two']\n",
    "    \n",
    "    weight = graph.get_edge_data(fst, snd)\n",
    "    \n",
    "    # print(weight)\n",
    "    \n",
    "    if weight == None: # devuelve 0 en caso de que no exista enlace\n",
    "        return 0\n",
    "    else: # si si existe, devuelve el peso\n",
    "        return weight['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_jn(row, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve el numero de vecinos en comun de esos dos nodos\n",
    "    \"\"\"\n",
    "    values_jn = nx.jaccard_coefficient(graph, [(row['one'], row['two'])])\n",
    "    \n",
    "    value_jn = 0\n",
    "    for u, v, p in values_jn:\n",
    "        value_jn = p # saco el valor\n",
    "        \n",
    "    return value_jn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pa(row, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve el valor de preferential attachment\n",
    "    \"\"\"\n",
    "    values_pa = nx.preferential_attachment(graph, [(row['one'], row['two'])])\n",
    "    \n",
    "    value_pa = 0\n",
    "    for u, v, p in values_pa:\n",
    "        value_pa = p # saco el valor\n",
    "        \n",
    "    return value_pa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_waa(row, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve para cada par de nodos, el valor de weighted adar adamic\n",
    "    \"\"\"\n",
    "    \n",
    "    # primero tengo que calcular los common neighbors de ambos items\n",
    "    cn_list = nx.common_neighbors(graph, row['one'], row['two'])\n",
    "    \n",
    "    # ahora tengo que hacer el sumatorio del valor para cada elemento de cn_list\n",
    "    value_waa = sum([((graph[row['one']][x]['weight'] + graph[row['two']][x]['weight']) / math.log(1 + graph.degree(x, weight=\"weight\"), 10) )  for x in cn_list])    \n",
    "    \n",
    "    \n",
    "    return value_waa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wcn(row, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve el numero de vecinos en comun de esos dos nodos\n",
    "    \"\"\"\n",
    "    cn_list = nx.common_neighbors(graph, row['one'], row['two'])\n",
    "    \n",
    "    value_wcn = sum([graph[row['one']][x]['weight'] + graph[row['two']][x]['weight'] for x in cn_list])\n",
    "    \n",
    "    return value_wcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wpa(row, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve el valor de weighted preferential attachment\n",
    "    \"\"\"\n",
    "    value_wpa = graph.degree(row[\"one\"], weight=\"weight\") * graph.degree(row[\"two\"], weight=\"weight\")\n",
    "        \n",
    "    return value_wpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_measure_data(graph):\n",
    "\n",
    "    \"\"\"\n",
    "        Function that builds a dataframe with all the combinations between the nodes.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Ahora voy a construir un DataFrame que tenga dos columnas con todas las posibles combinaciones de problemas, y otra \n",
    "    # columna con el valor de la medida especificada para ese par de problemas\n",
    "    fst_column = list()\n",
    "    snd_column = list()\n",
    "    for fst, snd in it.combinations(nodes, 2):\n",
    "        fst_column.append(fst)\n",
    "        snd_column.append(snd)\n",
    "\n",
    "    d = {'one' : fst_column,\n",
    "        'two' : snd_column}\n",
    "    dataFrame_measure = pd.DataFrame(d)\n",
    "\n",
    "    return dataFrame_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_measure(dataFrame_measure, measure):\n",
    "     \n",
    "    \"\"\"\n",
    "        Function that builds a dataframe with all the similarity values for two nodes.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Aplico la funcion a cada fila\n",
    "    if measure == 'aa':\n",
    "        # print(\"AA\")\n",
    "        dataFrame_measure['aa'] = dataFrame_measure.apply (lambda row: apply_aa(row, graph), axis=1)\n",
    "    elif measure == 'cn':\n",
    "        # print(\"CN\")\n",
    "        dataFrame_measure['cn'] = dataFrame_measure.apply (lambda row: apply_cn(row, graph), axis=1)\n",
    "    elif measure == 'ew':\n",
    "        # print(\"EW\")\n",
    "        dataFrame_measure['ew'] = dataFrame_measure.apply (lambda row: apply_ew(row, graph), axis=1)\n",
    "    elif measure == 'jn':    \n",
    "        # print(\"JN\")\n",
    "        dataFrame_measure['jn'] = dataFrame_measure.apply (lambda row: apply_jn(row, graph), axis=1)\n",
    "    elif measure == 'pa':    \n",
    "        # print(\"PA\")\n",
    "        dataFrame_measure['pa'] = dataFrame_measure.apply (lambda row: apply_pa(row, graph), axis=1)\n",
    "\n",
    "    elif measure == 'waa':\n",
    "        # print(\"WAA\")\n",
    "        dataFrame_measure['waa'] = dataFrame_measure.apply (lambda row: apply_waa(row, graph), axis=1)\n",
    "    elif measure == 'wcn':    \n",
    "        # print(\"WCN\")\n",
    "        dataFrame_measure['wcn'] = dataFrame_measure.apply (lambda row: apply_wcn(row, graph), axis=1)\n",
    "    elif measure == 'wpa':    \n",
    "        # print(\"WPA\")\n",
    "        dataFrame_measure['wpa'] = dataFrame_measure.apply (lambda row: apply_wpa(row, graph), axis=1)\n",
    "        \n",
    "    return dataFrame_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getrecommendations(row, measure_df, measure):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve la lista de k mejores problemas para el usuario\n",
    "    \"\"\"\n",
    "    \n",
    "    # primero saco los dos dataframes con problemas que se pueden recomendar\n",
    "    column_result_one = measure_df[measure_df['one'] == row['item']]\n",
    "    column_result_two = measure_df[measure_df['two'] == row['item']]\n",
    "    \n",
    "    \n",
    "    tmp1 = column_result_two['two'].tolist()\n",
    "    tmp2 = column_result_two['one'].tolist()\n",
    "    tmp3 = column_result_two[measure].tolist()\n",
    "   \n",
    "    # creo un nuevo df\n",
    "    df_tmp = pd.DataFrame({'one':tmp1, 'two':tmp2, measure: tmp3})\n",
    "    \n",
    "    frames = [column_result_one, df_tmp]\n",
    "    \n",
    "    # concateno los resultados\n",
    "    column_result_tmp = pd.concat(frames, sort=True)\n",
    "    \n",
    "    # ordeno los problemas que se pueden recomendar\n",
    "    column_result_tmp2 = column_result_tmp.sort_values(measure, ascending=False)\n",
    "     \n",
    "    tmp1 = column_result_tmp2['one'].tolist()\n",
    "    tmp2 = column_result_tmp2['two'].tolist()\n",
    "    tmp3 = column_result_tmp2[measure].tolist()\n",
    "    \n",
    "    # creo un nuevo df     \n",
    "    column_result = pd.DataFrame({'one':tmp1, 'two':tmp2, measure: tmp3})\n",
    "    \n",
    "    #column_result = column_result[column_result[measure] != 0]\n",
    "    \n",
    "    return (column_result['two'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_getrecommendations(df_new, measure_df, measure):\n",
    "    \"\"\"\n",
    "    Function to generate a new column with the list of recommendations for each user\n",
    "    \"\"\"\n",
    "    df_new['list_recommendations'] = df_new.apply(lambda row: getrecommendations(row, measure_df, measure), axis=1)\n",
    "    #print(\"Nueva lista recommendations\")\n",
    "    #print(df_new['list_recommendations'])\n",
    "    #print(df_new)\n",
    "    return df_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(l1, l2): \n",
    "    linter = [e for e in l1 if e in l2] \n",
    "    return linter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilarItems(item, user, df_measure, df_users):\n",
    "    # saco la lista de items mas similares a item\n",
    "    lista = df_measure[df_measure['item'] == item]['list_recommendations'].values \n",
    "    \n",
    "    sim_items_list = list()\n",
    "    \n",
    "    if (len(lista) != 0):\n",
    "        sim_items_list = lista[0]\n",
    "    \n",
    "    list_items_user = list()\n",
    "    \n",
    "    # ahora hago el filtro del usuario: solo me quedo con aquellos items con los que haya interactuado el usuario\n",
    "    # saco la lista de items con los que ha interactuado el usuario\n",
    "    if user in df_users:\n",
    "        list_items_user = df_users[user]\n",
    "    \n",
    "    # ahora, de los items similares, me quedo con los que ha hecho el usuario, manteniendo el orden, ya que \n",
    "    # los primeros son los mas similares\n",
    "    sim_items_user = intersection(sim_items_list, list_items_user)\n",
    "    \n",
    "    return sim_items_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKsim(sim_items, k):\n",
    "    \"\"\"\n",
    "        Funcion que saca las k mejores recomendaciones para el usuario\n",
    "        Lo que hace es coger los primeros k valores de la lista de recomendaciones\n",
    "    \"\"\"\n",
    "    if len(sim_items) == 0:\n",
    "        return []\n",
    "    else:\n",
    "        return sim_items[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKSize(max_list):\n",
    "    return len(max_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilar(predicted_df, dataframe_measures, measure, df_users):\n",
    "    \"\"\"\n",
    "         Calculo los items similares para una medida en concreto para un item en concreto, solo teneindo en cuenta aquellos\n",
    "         items con los que ha interactuado el usuario en el conjunto de entrenamiento.\n",
    "    \"\"\"\n",
    "    measure_idx = MEASURES.index(measure)\n",
    "    # print(predicted_df)\n",
    "    predicted_df['sim_items'] = predicted_df.apply(lambda row: getSimilarItems(int(row['item']), row['user'], dataframe_measures[measure_idx], df_users), axis=1)\n",
    "    \n",
    "    \n",
    "    # Crear una columna de 1 a 10 k\n",
    "    for k in range(1,K+1):\n",
    "        name = 'sim_items_' + str(k)\n",
    "        predicted_df[name] = predicted_df.apply(lambda row: getKsim(row['sim_items'], k), axis=1)\n",
    "    \n",
    "    predicted_df['list_size'] = predicted_df.apply(lambda row: getKSize(row['sim_items_10']), axis=1)\n",
    "    predicted_df_copy = predicted_df.drop(['sim_items'], axis=1)\n",
    "    \n",
    "    \n",
    "    return predicted_df_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgPredRating(user, sim_items, df_measure):\n",
    "    \"\"\"\n",
    "        Devuelve la media de los ratings predichos de los items similares\n",
    "    \"\"\"\n",
    "    # si no hay items \n",
    "    if len(sim_items) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        pred_ratings = list()\n",
    "        # para todos los elementos de la lista de items similares, calculo su rating real en el conjunto de entrenamiento\n",
    "        for elem in sim_items:\n",
    "            df_measure_user = df_measure[df_measure['user'] == user]\n",
    "            df_measure_user_item = df_measure_user[df_measure_user['item'] == elem]\n",
    "            \n",
    "            # si el user-item no esta en el conjunto de entrenamiento, pongo que su rating es cero\n",
    "            if df_measure_user_item.empty:\n",
    "                pred_ratings.append(0)\n",
    "            else:\n",
    "                pred_ratings.append(df_measure_user_item['rating'].values[0])\n",
    "                \n",
    "        # devuelvo la media de los valores de la lista\n",
    "        return sum(pred_ratings) / len(pred_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredRatings(dataframe_similar_items, measure, training_set):\n",
    "    \"\"\"\n",
    "        Funcion para obtener la media de ratings predichos para una lista de items similares\n",
    "    \"\"\"\n",
    "    # saco el dataframe para la medida seleccionada\n",
    "    measure_idx = MEASURES.index(measure)\n",
    "    df_measure = dataframe_similar_items[measure_idx]\n",
    "    \n",
    "    # de 1 a 10 similar items\n",
    "    for k in range(1,K+1):\n",
    "        name = 'avg_rating_' + str(k)\n",
    "        name_sim = 'sim_items_' + str(k)\n",
    "        # genero la media de los ratings reales en el conjunto de entrenamiento para los items similares\n",
    "        df_measure[name] = df_measure.apply(lambda row: avgPredRating(int(row['user']), row[name_sim], training_set), axis=1)\n",
    "        \n",
    "        \n",
    "    return df_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDifferenceRow(predicted, avg):\n",
    "    return pow(abs(predicted - avg),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDiffs(dataframe_similar_items, measure):\n",
    "    \"\"\"\n",
    "        Obtenemos tambien las diferencias entre el rating predicho del item de evaluacion y el avg de los items similares\n",
    "    \"\"\"\n",
    "    # saco el dataframe para la medida seleccionada\n",
    "    measure_idx = MEASURES.index(measure)\n",
    "    df_measure = dataframe_similar_items[measure_idx]\n",
    "    \n",
    "    # de 1 a 10 similar items\n",
    "    for k in range(1,K+1):\n",
    "        name_dif = 'diff_' + str(k)\n",
    "        name_avg = 'avg_rating_' + str(k)\n",
    "        name_sim = 'sim_items_' + str(k)\n",
    "        \n",
    "        # elimino la columna con los items similares, ya que ya no lo necesitamos\n",
    "        df_measure.drop([name_sim], axis=1, inplace=True)\n",
    "        \n",
    "\n",
    "        # genero la media de los ratings reales en el conjunto de entrenamiento para los items similares\n",
    "        df_measure[name_dif] = df_measure.apply(lambda row: getDifferenceRow(row['predicted'], row[name_avg]), axis=1)\n",
    "        \n",
    "    return df_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_list(l):\n",
    "    return sum(l) / float(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRMSE(df_diffs, measure):\n",
    "    \"\"\"\n",
    "        Funcion que obtiene la media de las diferencias: RMSE para k = 1..10 y medidas de similitud = MEASURES\n",
    "    \"\"\"\n",
    "    # saco el dataframe para la medida seleccionada\n",
    "    measure_idx = MEASURES.index(measure)\n",
    "    df_diff_measure = df_diffs[measure_idx]\n",
    "    lista_sizes = df_diff_measure['list_size'].tolist()\n",
    "    \n",
    "    len_lista_sizes = len(lista_sizes)\n",
    "    \n",
    "    rmse_avg = list()\n",
    "    \n",
    "    # de 1 a 10 similar items\n",
    "    for k in range(1,K+1):\n",
    "        name_dif = 'diff_' + str(k)        \n",
    "        \n",
    "        # aqui no tengo que coger las diferencias de los usuarios que no tienen una lista con tamaño >= k\n",
    "        lista_diffs = df_diff_measure[name_dif].tolist()\n",
    "        tmp = list()\n",
    "        for i in range(len_lista_sizes):\n",
    "            if(lista_sizes[i] >= k):\n",
    "                tmp.append(lista_diffs[i])\n",
    "        \n",
    "        # concateno a la lista el valor de rmse para k\n",
    "        rmse_avg.append(math.sqrt(mean_list(tmp)))\n",
    "        \n",
    "    return rmse_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask(total_elems, num_elems):\n",
    "    random_values = np.random.rand(total_elems)\n",
    "    \n",
    "    if total_elems == num_elems:\n",
    "        return np.full((35), True)\n",
    "    else:\n",
    "        border = np.sort(random_values)[num_elems]\n",
    "        mask = random_values < border\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para seleccionar aleatoriamente el test estratificado\n",
    "def get_estratificate_populate(dataframe, measure, num_elems=35):\n",
    "\n",
    "    finaldf = pd.DataFrame(columns=dataframe.columns)\n",
    "    \n",
    "    ratings_values = list(set(dataframe['rating']))\n",
    "    ratings_values.sort()\n",
    "    \n",
    "    for r in ratings_values:\n",
    "        \n",
    "        rating_df = dataframe[dataframe['rating'] == r]\n",
    "        \n",
    "        # Solo añadimos ratings con representación mayor o igual a num_elems\n",
    "        if len(rating_df) >= num_elems:\n",
    "            mask = make_mask(len(rating_df), num_elems)\n",
    "            finaldf = finaldf.append(rating_df[mask])\n",
    "    \n",
    "    return finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estratificate_populate_100(df_diffs, measure, num_elems=35):\n",
    "    \n",
    "    measure_idx = MEASURES.index(measure)\n",
    "    dataframe = dataframe_similar_items[measure_idx]\n",
    "    \n",
    "    final_df = pd.DataFrame(columns=dataframe.columns)\n",
    "    for i in range(0, 100):\n",
    "        estratificado = get_estratificate_populate(dataframe, measure, num_elems=35)\n",
    "        final_df = final_df.append(estratificado)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to split the dataset into training set and evaluation set\n",
    "# I am going to use the first half of ratings to build the training set and the second one to build the evaluation set\n",
    "\n",
    "# I build the training set\n",
    "training_set = pd.read_csv('trainset.csv')\n",
    "\n",
    "# I delete the ratings with values < 4 (movies with ratings < 4 are not interested to users)\n",
    "#training_set = training_set[training_set['rating'] >= RATING_THRESHOLD]\n",
    "\n",
    "training_set.columns = ['user', 'item', 'rating', 'timestamp']\n",
    "\n",
    "#print(training_set)\n",
    "#training_set[training_set['user'] == 545]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I build the evaluation_set\n",
    "#evaluation_set = df[HALF_DATASET_SIZE:]\n",
    "\n",
    "# evaluation_set = evaluation_set[evaluation_set['rating'] != 0.5]\n",
    "\n",
    "# evaluation_set = pd.read_csv('testset.csv')\n",
    "evaluation_set = pd.read_csv('testset_stratified.csv')\n",
    "\n",
    "evaluation_set.columns = ['user', 'item', 'rating', 'timestamp']\n",
    "\n",
    "# print(evaluation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estratificado fijo con 35 dilas para cada rating\n",
    "# predicted_df_original = pd.read_csv('predicted_values_clean.csv', sep=';')\n",
    "predicted_df_original = pd.read_csv('predicted_values.csv')\n",
    "\n",
    "predicted_df_original.columns = ['user', 'item', 'rating', 'predicted']\n",
    "\n",
    "predicted_df = predicted_df_original.copy()\n",
    "# print(predicted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = pd.merge(evaluation_set, predicted_df_original, how='inner', on=['user', 'item'])\n",
    "\n",
    "del predicted_df['rating_y']\n",
    "\n",
    "predicted_df.columns = ['user', 'item', 'rating', 'timestamp', 'predicted']\n",
    "\n",
    "# predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I get the list of nodes\n",
    "nodes = training_set.item.unique()\n",
    "\n",
    "# print(len(nodes))\n",
    "# print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I create a dictionary: keys are the items, and values are the list of users that are interacted with this item\n",
    "grouped = training_set.groupby('item')['user'].apply(list)\n",
    "\n",
    "#print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I create the links with the suitable format for nx\n",
    "links = createLinks(grouped, nodes, WEIGHT_THRESHOLD)\n",
    "\n",
    "# print(len(links))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I create the graph\n",
    "graph = create_graph_nx(nodes, links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_user = training_set.groupby('user')['item'].apply(list)\n",
    "\n",
    "# diccionario que va a contener como key el user, como value, los items con los que ha interactuado el user\n",
    "df_users = {}\n",
    "df_users_l = {}\n",
    "\n",
    "for i,j in zip(grouped_user.index.tolist(), grouped_user.values.tolist()):\n",
    "    df_users[i] = j \n",
    "    #if len(j) >= 10:\n",
    "        #df_users_l[i] = len(j) \n",
    "#df_users_l_list = list(df_users_l.keys())\n",
    "#df_users_l_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'item': list(set(training_set['item'].tolist()))}\n",
    "df_similar = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I create a dataframe that keeps the similarity values from the measures\n",
    "\n",
    "# I add columns with the similarity values for each row\n",
    "measure_df = create_measure_data(graph)\n",
    "\n",
    "measure_df = apply_measure(measure_df, 'cn') \n",
    "\n",
    "#print(measure_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df = apply_measure(measure_df, 'ew') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df = apply_measure(measure_df, 'aa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df = apply_measure(measure_df, 'jn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df = apply_measure(measure_df, 'pa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df = apply_measure(measure_df, 'wcn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df = apply_measure(measure_df, 'waa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df = apply_measure(measure_df, 'wpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I build a list of list: rows for k, columns for measures\n",
    "# k --> 1 a 10 (0 a 9)\n",
    "# measures --> cn, ew, aa, jn, pa, wcn, waa, wpa (0 a 7)\n",
    "# each cell has a dataframe for k = i and measure = j\n",
    "\n",
    "dataframe_measures = list()\n",
    "\n",
    "# creo una lista en cada posicion, en esa lista vamos a guardar los valores para las measures \n",
    "# obtenemos las recomendaciones para cada celda\n",
    "# creo una copia par que no se modifiquen las referencias de los dataframes\n",
    "dataframe_measures = [apply_getrecommendations(df_similar, measure_df, measure).copy() for measure in MEASURES] \n",
    "\n",
    "# en esta estructura tengo:\n",
    "# por cada fila: las diferentes metricas de similitud\n",
    "# guardo cuales son los items mas similares a uno dado \n",
    "# print(dataframe_measures)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUATION ########################################################### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devolvemos una lista de dataframes en la que se incluyen los items similares\n",
    "# .copy()\n",
    "dataframe_similar_items = [getSimilar(predicted_df, dataframe_measures, measure, df_users) for measure in MEASURES]\n",
    "# dataframe_similar_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similar_items_rating = [getPredRatings(dataframe_similar_items, measure, training_set) for measure in MEASURES]\n",
    "# df_similar_items_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diffs = [getDiffs(df_similar_items_rating, measure) for measure in MEASURES]\n",
    "# df_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estratificado aleatorio\n",
    "df_diffs = [get_estratificate_populate_100(df_diffs, measure, num_elems=35) for measure in MEASURES]\n",
    "# df_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = [getRMSE(df_diffs, measure) for measure in MEASURES]\n",
    "# RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RMSE = pd.DataFrame(RMSE)\n",
    "df_RMSE.columns= [1,2,3,4,5,6,7,8,9,10]\n",
    "df_RMSE['sim_measure'] = MEASURES\n",
    "# df_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_RMSE.to_csv('RMSE_item_graph_estratificado_p.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
